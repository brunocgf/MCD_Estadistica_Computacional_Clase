---
title: "Examen Final"
author: "Bruno C. Gonzalez"
date: "4/12/2019"
output: pdf_document
---

## Final

```{r, include=FALSE}
library(nullabor)
library(rstan)
library(bayesplot)
library(arm)
library(tidyverse)
library(glue)
library(sampler)
library(pps)
set.seed(51)
```


### 1. Inferencia gráfica

1. **Preparación de los datos**.  

```{r, message=FALSE}
wages <- read_csv("data/wages.csv",
                  col_types = cols(
                    id = col_integer(),
                    lnw = col_double(),
                    exper = col_double(),
                    ged = col_double(),
                    postexp = col_double(),
                    black = col_integer(),
                    hispanic = col_integer(),
                    hgc = col_integer(),
                    hgc.9 = col_integer()
                  ))
```

* Selecciona los sujetos con grado de estudios completado igual a 9, 10 u 11.

```{r}
tidy_wages <- wages %>% 
  filter(hgc >= 9, hgc <=11) %>% 
  dplyr::select(1:8)
```


* Elimina las observaciones donde el logaritmo del salario (lnw) es mayor a 3.5.

```{r}
tidy_wages <- tidy_wages %>% 
  filter(lnw <= 3.5)
```

* Crea una variable correspondiente a raza, un sujeto es de raza hispana si la variable hispanic toma el valor 1, de raza negra si la variable black toma el valor 1 y de raza blanca si las dos anteriores son cero.

```{r}
tidy_wages <- tidy_wages %>% 
  mutate(raza = ifelse(hispanic==1,'hispana',ifelse(black==1,'negra','blanca')))
```

* Crea un subconjunto de la base de datos de tal manera que tengas el mismo número de sujetos distintos en cada grupo de raza. Nota: habrá el mismo número de sujetos en cada grupo pero el número de observaciones puede diferir pues los sujetos fueron visitados un número distinto de veces. 

Primero creamos una función que tomo como variable el número de sujetos que se desean incluir

```{r, message=FALSE}

f_wages_sample <- function(n=10){
  sample <- tidy_wages %>% 
    group_by(id, raza) %>% 
    summarize() %>%
    ungroup() %>% 
    group_by(raza) %>% 
    sample_n(n)
  
  tidy_wages %>% 
    semi_join(sample)
}

```
Posteriormente creamos el subconjunto de datos.

```{r, message=FALSE}
sample_wages <- f_wages_sample(80)
```


2 **Prueba de hipótesis visual**

```{r, eval=FALSE, echo=FALSE}
ggplot(sample_wages, aes(x = exper, y = lnw)) +
  geom_point(alpha = 0.3, size = 1.5) + 
  geom_smooth(aes(group = raza, color = raza), method = "loess", se = FALSE) +
  theme_light()
```



* El escenario nulo consiste en que no hay diferencia entre las razas. Para generar los datos nulos, la etiqueta de raza de cada sujeto se permuta, es decir, se reasigna la raza de cada sujeto de manera aleatoria (para todas las mediciones de un sujeto dado se reasigna una misma raza). Genera 9 conjuntos de datos nulos y para cada uno ajusta una curva _loess_ siguiendo la instrucción de
la gráfica de arriba. Crea una gráfica de paneles donde incluyas los 9 conjuntos nulos y los datos reales, estos últimos estarán escondidos de manera aleatoria.

Primero creamos los datos nulos

```{r, message=FALSE}
null_wages <- lineup(null_permute('raza'),
                     n = 10,
                     sample_wages)
```

A continuación hacemos las gráficas correspondientes

```{r, message=FALSE, warning=FALSE, results = 'hide'}
ggplot(null_wages, aes(x = exper, y = lnw)) +
  geom_point(alpha = 0.2, size = 0.8) + 
  geom_smooth(aes(group = raza, color = raza), method = "loess", se = FALSE, size=0.5) +
  facet_wrap(~.sample) +
  theme_light()
```


```{r, eval=FALSE, echo=FALSE}
attr(null_wages,"pos")
```

* Realiza la siguiente pregunta a una o más personas __que no tomen la clase__:

_Las siguientes 10 gráficas muestran suavizamientos de log(salarios) por años
de experiencia laboral. Una de ellas usa datos reales y las otras 9 son datos
nulos, generados bajo el supuesto de que no existe diferencia entre los
subgrupos. ¿Cuál es la gráfica más distinta?

Reporta si las personas cuestionadas pudieron distinguir los datos.
Se le preguntó a 5 personas, de las cuales solo 2 pudieron distinguir los datos correctos.

* ¿Cuál es tu conclusión de la prueba de hipótesis visual?
No se puede rechazar la hipotesis nula, por lo que no se puede deducir que existe diferencia en los salarios con base en los años trabajados entre los subgrupos.

* ¿A cuántas personas preguntaste y cuál es el valor p de la prueba?
Dado que solo 2 personas de 5 distinguieron la gráfica con los datos reales (rechazaron la hipótesis nula), el vaolor p es de $0.6$.


### 2. Simulación para el cálculo de tamaños de muestra

Utilizarás simulación y los resultados de las elecciones de gobernador en Guanajuato correspondientes al 2012. En el caso de **MAS**, para cada tamaño de muestra $n=50,100,200,300,400,500,600,700$:

i. Simula una muestra aleatoria de tamaño $n$.

```{r}
gto_2012 <- read.csv("./data/gto_2012.csv")

muestra <- map(c(50,100,200,300,400,500,600,700), ~sample_n(gto_2012,.))
glimpse(muestra[[1]])
```

La lista muestra contiene todas las muestras, solo se mustra el resumen de la primera.

ii. Calcula el estimador de razón (correspondiente a muestreo aleatorio simple) para cada candidato:

$$\hat{p}=\frac{\sum_{i} Y_{i}}{\sum_i X_{i}}$$
$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$

Primero definimos una función para calcular la muestra

```{r}

estimador<-function(data,size){
  data %>%
    sample_n(size) %>%
    mutate(muestra=glue("muestra_{size}")) %>%
    summarise(p_pri=sum(pri_pvem)/sum(total),p_pan=sum(pan_na)/sum(total),
              p_prd=sum(prd)/sum(total),p_pt=sum(pt)/sum(total),
              p_mc=sum(mc)/sum(total),p_otros=sum(otros)/sum(total)) %>% 
    select(p_pri,p_pan,p_prd,p_pt,p_mc,p_otros)
}

```

Con esta función podemos calcular los estimadores para la muestra que se desee.

```{r}
estimador(gto_2012, 50)
```


iii. Repite los pasos i y ii $1000$ veces para estimar el error estándar para
una muestra de tamaño $n$.

```{r}
m_50<-rerun(1000,estimador(gto_2012,50)) %>% 
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                                                                 se_mc=sd(p_mc),
                                                                 se_otros=sd(p_otros))
m_100<-rerun(1000,estimador(gto_2012,100)) %>% 
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                                                                  se_mc=sd(p_mc),
                                                                  se_otros=sd(p_otros))
m_200<-rerun(1000,estimador(gto_2012,200)) %>% 
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

m_300<-rerun(1000,estimador(gto_2012,300)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                                                                  se_mc=sd(p_mc),
                                                                  se_otros=sd(p_otros))
m_400<-rerun(1000,estimador(gto_2012,400)) %>% 
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                                                                  se_mc=sd(p_mc),
                                                                  se_otros=sd(p_otros))
m_500<-rerun(1000,estimador(gto_2012,500)) %>% 
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                                                                  se_mc=sd(p_mc),
                                                                  se_otros=sd(p_otros))
m_600<-rerun(1000,estimador(gto_2012,600)) %>% 
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                                                                  se_mc=sd(p_mc),
                                                                  se_otros=sd(p_otros))
m_700<-rerun(1000,estimador(gto_2012,700)) %>% 
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                                                                  se_mc=sd(p_mc),
                                                                  se_otros=sd(p_otros))
```

Así, el error estadar para cada una de las muestras será:

```{r}
MAS_se <- rbind(m_50,m_100,m_200,m_300,m_400,m_500,m_600,m_700)
rownames(MAS_se) <- c('50','100','200','300','400','500','600','700')
MAS_se
```


Para cada **estratificación** (`distrito_fed_17` y `distrito_loc_17`) y tamaño de muestra $n=50,100,200,300,400,500,600,700$:

i. Simula una muestra estratificada de tamaño $n$, donde el tamaño de muestra en cada estrato se asigna proporcional al tamaño del estrato, esto es, sea $N_h$ el número de casillas en el $h$-ésimo estrato, entonces para el estrato $h$ el número de casillas en la muestra será:
$$n_h = N_h \cdot \frac{n}{\sum_j N_j}$$
ii. Calcula el estimador de razón combinado (correspondiente a muestreo estratificado) para cada candidato:

$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$


iii. Repite los pasos i y ii $1000$ veces para estimar el error estándar para una muestra de tamaño $n$.

Agrupamos el dataset por los estratos solicitados
```{r}
####### muestra por estratos ########
by_stratum_dist_17<-gto_2012 %>% 
  group_by(distrito_fed_17) %>% 
  arrange(distrito_fed_17)

by_stratum_local_17<-gto_2012 %>% 
  group_by(distrito_loc_17) %>% 
  arrange(distrito_loc_17)
```

Encontramos la n proporcional a cada estrato con las diferentes muestras.

```{r}
#Para el estrato distrito fed 17:
size_estrato_fed_17<-ssampcalc(df = gto_2012,n =50,strata = distrito_fed_17) %>%
  cbind(ssampcalc(df = gto_2012,n =100,strata = distrito_fed_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n =200,strata = distrito_fed_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n =300,strata = distrito_fed_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n =400,strata = distrito_fed_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n =500,strata = distrito_fed_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n =600,strata = distrito_fed_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n =700,strata = distrito_fed_17)[,4]) 

names(size_estrato_fed_17)<-c("distrito_fed_17","Nh","wt","nh_50","nh_100","nh_200","nh_300","nh_400",
         "nh_500","nh_600","nh_700")

size_estrato_fed_17
```

```{r}
#Para el estrato distrito loc 17:
size_estrato_loc_17<-ssampcalc(df = gto_2012,n = 50,strata = distrito_loc_17) %>%
  cbind(ssampcalc(df = gto_2012,n = 100,strata = distrito_loc_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n = 200,strata = distrito_loc_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n = 300,strata = distrito_loc_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n = 400,strata = distrito_loc_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n = 500,strata = distrito_loc_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n = 600,strata = distrito_loc_17)[,4]) %>%
  cbind(ssampcalc(df = gto_2012,n = 700,strata = distrito_loc_17)[,4])

names(size_estrato_loc_17)<-c("distrito_loc_17","Nh","wt","nh_50","nh_100","nh_200","nh_300","nh_400",
                              "nh_500","nh_600","nh_700")

size_estrato_loc_17
```

Función Muestra simulada proporcional a los estratos
```{r}
set.seed(141394)
estimador_strata<-function(stratum,nh,data){
  index_<-stratsrs(stratum,nh)
  data[index_,] %>% 
    summarise(p_pri=sum(pri_pvem)/sum(total),p_pan=sum(pan_na)/sum(total),
                             p_prd=sum(prd)/sum(total),p_pt=sum(pt)/sum(total),
                             p_mc=sum(mc)/sum(total),p_otros=sum(otros)/sum(total)) %>% 
    select(p_pri,p_pan,p_prd,p_pt,p_mc,p_otros)
}
```

```{r}
#Estrado distrito federal 17
st1_50<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                    size_estrato_fed_17$nh_50,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
                        se_mc=sd(p_mc),
                        se_otros=sd(p_otros))

st1_100<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                    size_estrato_fed_17$nh_100,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st1_200<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                    size_estrato_fed_17$nh_200,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st1_300<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                    size_estrato_fed_17$nh_300,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st1_400<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                    size_estrato_fed_17$nh_400,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st1_500<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                    size_estrato_fed_17$nh_500,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st1_600<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                    size_estrato_fed_17$nh_600,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st1_700<-rerun(1000,estimador_strata(by_stratum_dist_17$distrito_fed_17,
                                     size_estrato_fed_17$nh_700,by_stratum_dist_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))
```

```{r, cache = TRUE}
#Estrado distrito local 17

st2_50<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_50,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st2_100<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_100,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st2_200<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_200,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st2_300<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_300,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st2_400<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_400,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st2_500<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_500,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st2_600<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_600,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))

st2_700<-rerun(1000,estimador_strata(by_stratum_local_17$distrito_loc_17,
                                    size_estrato_loc_17$nh_700,by_stratum_local_17)) %>%
  bind_rows() %>% 
  summarise(se_pri=sd(p_pri),se_pan=sd(p_pan),se_prd=sd(p_prd),se_pt=sd(p_pt),
            se_mc=sd(p_mc),
            se_otros=sd(p_otros))
```


Ahora:

1. Reporta en una tabla el error estándar para cada candidato, tamaño de muestra y diseño (MAS y las dos estratificaciones propuestas).

```{r}
tablaSe<-m_50 %>% 
  rbind(m_100,m_200,m_300,m_400,m_500,m_600,m_700,st1_50,st1_100,st1_200,st1_300,st1_400,st1_500,st1_600,st1_700,
        st2_50,st2_100,st2_200,st2_300,st2_400,st2_500,st2_600,st2_700)
tablaSe$sample <-c("MAS","MAS","MAS","MAS","MAS","MAS","MAS","MAS",
                    "1ST","1ST","1ST","1ST","1ST","1ST","1ST","1ST",
                    "2ST","2ST","2ST","2ST","2ST","2ST","2ST","2ST")
tablaSe$n<-c(50,100,200,300,400,500,600,700,50,100,200,300,400,500,600,700,50,100,200,300,400,500,600,700)

tablaSe
```


2. Grafica los datos de la tabla: realiza una gráfica de paneles (con `facet_wrap()`), cada partido en un panel, en el eje horizontal grafica el tamaño de muestra y en el eje vertical el error estándar, tendrás en una misma gráfica tres curvas, una para muestreo aleatorio simple y una para
cada estratificación.

```{r}
new_table<-tablaSe %>% gather(key =partido,value=se,se_pri:se_otros)

new_table %>% ggplot(aes(x=n,y=se))+
  geom_line(aes(x=n,y=se,colour=sample))+
  facet_wrap(~partido)+
  labs(title="Gráfica 2.1 Errores Estándar para cada tipo de muestreo",y="Error Estandar",x="Tamaño de la muestra")
```

3. ¿Qué diseño y tamaño de muestra elegirías? Explica tu respuesta y de ser necesario repite los pasos i-iii para otros valores de $n$.

Si nos fueramos por elegir el diseño que minimiza el error estándar se escogería el diseño de muestreo aleatorio simple(MAS), dado que en la gráfica 2.1 es el método que tiene menor error en los 6 partidos. Esto también se pudo generar porque las muestras de cada estrato no son muy homogéneos, por lo que MAS es más preciso que las estratificaciones y si nos fueramos por la estratificación no sería una buena extrapolación de la población.

### 3. MCMC

Siguiendo con el conteo rápido de Guanajuato, calcularás intervalos de confianza usando el modelo propuesto en @mendoza2016.

Los autores proponen ajustar un modelo de manera independiente para cada candidato en cada estrato:

* Verosimilitud

$$X_{ij}^k\big|\theta_{ij},\tau_{ij}\sim N\bigg(n_i^k\theta_{ij}, \frac{\tau_{ij}}{n_i^k}\bigg)$$

para $k=1,...,c_i$, $i = 1,...,N$, $j=1,...,J$

* Iniciales

$$p(\theta_{i,j},\tau_{ij})\propto \tau_{ij}^{-1}I(\tau_{ij}>0)I(0<\theta_{i,j}<1)$$

* Posterior

$$p(\theta_{ij}, \tau_{ij}|X_{ij}) \sim N\bigg(\theta_{ij} \bigg| \frac{\sum_{k=1}^{c_i}x_{ij}^k}{\sum_{k=1}^{c_i}n_{i}^k}, \tau_{ij}\sum_{k=1}^{c_i}n_i^k\bigg)I(0<\theta_{ij}<1)\times Ga\bigg(\tau_{ij}\bigg|\frac{c_i-1}{2}, \frac{1}{2}\bigg[\sum_{k=1}^{c_i}\frac{(x_{ij}^k)^2}{n_i^k}-\frac{\big(\sum_{k=1}^{c_i}x_{ij}^k\big)^2}{\sum_{k=1}^{c_i}n_i^k}\bigg]\bigg)$$


Implementa el modelo y estima los resultados electorales de Guanajuato con la muestra:

```{r, include=FALSE}
gto_muestra <- read_csv("data/muestra_gto_2012.csv")
```

Reporta estimaciones puntuales (media posterior) e intervalos del 95% de credibilidad para cada candidato.

Primereo definimos la distribución inicial.

```{r}
prior <- function(tau){
  function(theta){
    (1/tau)*ifelse(tau>0,1,0)*ifelse(theta>0&theta<1,1,0)
  }
}
```

Ahora difinimos la función para la verosimilitud.

```{r}
likelihood <- function(Xk,nk,tau,c){
  function(theta){
    pnorm(theta,tau*nk)*ifelse(theta>0&theta<1,1,0)*rgamma(tau,(Xk^2/nk - Xk^2/nk)/2)
  }
}
```


### 4. Modelos jerárquicos, Stan y evaluación de ajuste

#### Implementación

```{r, include=FALSE}
# preparación de los datos
library(haven)
# datos de encuestas
polls <- read_dta("./data/polls.dta")
# nos quedamos con la última encuesta y eliminamos faltantes
last_poll <- polls %>%
    filter(survey == 8) %>%
    mutate(age_edu = paste0(age, edu),
      age_edu_int = as.integer(as.factor(age_edu))) %>%
    na.omit()

# datos de elecciones pasadas para utilizar como covariable y variable región
presvote <- read_dta("./data/presvote.dta") %>%
    cbind(region = c(3,4,4,3,4,4,1,1,5,3,3,4,4,2,2,2,2,3,3,1,1,1,2,2,3,2,4,2,4,
        1,1,4,1,3,2,2,3,4,1,1,3,2,3,3,4,1,3,4,1,2,4))
```


```{r, include=FALSE}
x_person <- model.matrix(~ female + black + female * black, data = last_poll)
x_state <- model.matrix(~ -1 + factor(region) + g76_84pr, data = presvote) 


data_list <- list(
    n = nrow(last_poll), 
    n_age = n_distinct(last_poll$age),
    n_age_edu = n_distinct(last_poll$age_edu_int),
    n_edu = n_distinct(last_poll$edu), 
    n_state = max(last_poll$state), 
    mh = 3, 
    mm = 6, 
    age = last_poll$age,
    edu = last_poll$edu,
    age_edu = last_poll$age_edu_int,
    state = last_poll$state, 
    y = last_poll$bush, 
    x_person = x_person[, -1],
    x_state = x_state
)
```


1. **Modelo**. Ajusta el modelo y revisa convergencia, describe cuantas cadenas, iteraciones y etapa de calentamiento elegiste, además escribe como determinaste convergencia.

Primero definimos el modelo.

```{r, cache = TRUE}
model_mrp <- stan_model('model_mrp.stan')
```

Posteriormente se corre el modelo con los datos.

```{r, warning=FALSE, message=FALSE}
model_mrp_fit <- sampling(model_mrp,
                          data = data_list,
                          chains = 3,
                          warmup = 500,
                          iter = 1500)
```

Primero evaluamos usando *traceplot*.

```{r, eval=FALSE}
traceplot(model_mrp_fit)
```

En todos los cassos los parmámetros parecen converger. Igualmente podemos revisar el diagnóstico de convergencia Gelman-Rubin.

```{r, cache=TRUE}
mcmc_rhat(rhat(model_mrp_fit))
```


En todos los casos $\hat{R}$ es menor a $1.1$ por lo que se puede comprobar la convergencia. Ahora revisemos el tamaño efectivo de la muestra.

```{r}
mcmc_neff(neff_ratio(model_mrp_fit))
```


Este indicador es equivalente al visto en clase pero queremos que sea mayor a $0.1$, por lo que se puede confiar en estimaciones estables. De esta manera se eligieron las corridas y calemntamientos mínimos para lograr estos resultados.

2. **Evaluación de ajuste**. Usaremos la distribución predictiva posterior para simular de modelo y comparar con los datos observados. En particular veremos como se comparan las simulaciones del modelo por estado, la gráfica con los datos será la que sigue:

```{r, include=FALSE}
bush_state <- last_poll %>%
    group_by(state) %>%
    summarise(prop = mean(bush, na.rm = TRUE)) %>%
    ungroup() %>%
    mutate(state_ord = as.numeric(reorder(state, prop)))

ggplot(bush_state, aes(x = state_ord, y = prop)) +
    geom_line()
```

Debes simular del modelo 10 conjutos de datos del tamaño de los originales (replicaciones de los datos) y hacer una gráfica de páneles donde muestres los datos originales y las replicaciones, ¿que concluyes al ver la gráfica?

Primero obtenemos los parámetros *reg_pred* y los acomodamos en una tabla.

```{r}
state <- tibble(id = 1:2015, state = last_poll$state)

par_sim <- as.data.frame(model_mrp_fit, pars = 'reg_pred') %>% 
  mutate(n_sim = 1:n()) %>% 
  filter(n_sim <= 10) %>% 
  pivot_longer(cols = -n_sim, names_to = "id", values_to = "reg_pred", names_prefix = 'reg_pred') %>%   mutate(id = parse_number(id)) %>% 
  left_join(state, by = 'id') %>% 
  mutate(y = invlogit(reg_pred)) %>% 
  group_by(n_sim, state) %>%
  summarise(prop = mean(y)) %>%
  ungroup() %>%
  arrange(n_sim, prop) %>% 
  mutate(state_ord = rep(1:49,10))

bush_state$n_sim <- 'orig'

par_sim <- rbind(par_sim, bush_state)

```

Posteriormente hacemos la gráfica.

```{r}
ggplot(par_sim, aes(x = state_ord, y = prop)) +
  geom_line() +
  facet_wrap(~n_sim) +
  theme_light()
```




3. El siguiente código predice para cada celda de la tabla del censo, vale la pena notar, que para cada celda tenemos una lista en el vector `pred` con las simuaciones que le corresponden.

```{r, include = FALSE}
 # construct the n.sims x 3264 matrix
census88 <- read_dta("./data/census88.dta")

params_sims <- as.data.frame(model_mrp_fit, pars = c("beta_0", "beta", "beta_age", 
    "beta_edu", "beta_age_edu", "beta_state"))


pred_cell <- census88 %>% 
    mutate(age_edu = paste0(age, edu), 
        age_edu_int = as.integer(as.factor(age_edu))) %>% 
    rowwise() %>% 
    mutate(
        pred = list(invlogit(params_sims$beta_0 + 
                params_sims$`beta[1]` * female +
                params_sims$`beta[2]` * black + 
                params_sims$`beta[3]` * female * black +
                params_sims[, str_c("beta_age[", round(age), "]")] +
                params_sims[, str_c("beta_edu[", round(edu), "]")] +  
                params_sims[, str_c("beta_age_edu[", age_edu_int, "]")] +  
                params_sims[, str_c("beta_state[", round(state), "]")]))
    ) 
```

Para hacer las estimaciones por estado hace falta ponderar por el número de casos en cada celda:

$$\theta_s=\frac{\sum_{j \in s}N_{j}\pi_j}{\sum_{j \in s}N_{j}}$$

4. Genera las simulaciones de $\theta_s$, recuerda que debarás calcular una simulación de cada $\theta_s$ por cada simulación de $\pi_j$ obtenida con el código de arriba. Realiza una gráfica con intervalos de credibilidad del 95% para cada $theta_s$.

Primero construimos una función que ayudará a obtener las tetas para cada simulación
```{r}

f_theta <- function(i){
  pred_cell %>% 
    mutate(Num = N*pred[i]) %>% 
    group_by(state) %>% 
    summarise(theta_s = sum(Num)/sum(N))
}
```

Ahora obtenemos las thetas

```{r, warning=FALSE, message=FALSE}
theta <- map(1:3000,f_theta) %>% 
  bind_rows(.id='sim') %>% 
  group_by(state) %>% 
  summarise(
    media = mean(theta_s),
    int_l = quantile(theta_s,0.025),
    int_u = quantile(theta_s,0.975)
  )
```

Por último realizamosla gráfica de intervalos por estado.

```{r}
ggplot(theta, aes(x = reorder(state,media), y = media, color = factor(state))) +
  geom_pointrange(aes(ymin=int_l, ymax = int_u), size = 0.3) +
  geom_point(color = 'black') +
  theme(legend.position = "none") +
  theme_light()
```

