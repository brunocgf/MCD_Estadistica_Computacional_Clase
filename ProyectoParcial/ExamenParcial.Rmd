---
title: "ExamenParcial"
author: "Bruno Gonzalez"
date: "2/10/2019"
output:
  html_document: default

---

```{r packetes, include = FALSE}
library(tidyverse)
library(FactoMineR)
library(knitr)
library(boot)
```

## EXAMEN PARCIAL


#### 1. Tablas de conteos y bootstrap {-}

En la sección de visualización vimos un ejemplo de tabla de perfiles.

En este ejercicio construiremos intervalos de confianza para una tabla de perfiles usando bootstrap. Usaremos los datos de tomadores de te (del paquete @factominer):

```{r data_tea}
data(tea)
tea <- tea %>% 
  as_tibble %>% 
  select(how, price, sugar)
```

Nos interesa ver qué personas compran té suelto (`unpacked`), y de qué tipo (`Tea`). Empezamos por ver las proporciones que compran té según su empaque (en bolsita o suelto):

```{r tabla_tea, echo = FALSE, warning=FALSE, message=FALSE}
tipo <- tea %>% 
  count(how) %>% 
  mutate(`%` = round(100 * n / sum(n)))
tipo %>% kable()
```

La tabla de arriba es poco informativa, buscamos comparar grupos, por ejemplo, queremos investigar si hay diferencias en los patrones de compra (en términos de precio o marca) dependiendo del tipo de té que consumen.

```{r tabla_perfiles, echo = FALSE, warning=FALSE, message=FALSE}
tipo <- tipo %>% select(how, prop_how = `%`)
tabla_2 <- tea %>%
  count(how, price) %>% 
  group_by(how) %>% 
  mutate(prop = round(100 * n / sum(n))) %>% 
  select(-n) 
tabla_2 %>% spread(how, prop, fill = 0)
```

Para facilitar la comparación podemos calcular *perfiles columna*. Comparamos cada una de las columnas con la columna marginal (la tabla de tipo de estilo de té):

```{r tabla_perfile2, echo=FALSE, message = FALSE, warning=FALSE}
tabla <- tea %>% 
  count(how, price) %>% 
  group_by(how) %>% 
  mutate(prop_price = (100 * n / sum(n))) %>% 
  group_by(price) %>% 
  mutate(prom_prop = mean(prop_price)) %>% 
  mutate(perfil = (prop_price / prom_prop - 1) %>% round(2))  
```

```{r kable_perfiles, echo = FALSE, message = FALSE, warning=FALSE}
precio_prom <- tabla %>% 
  distinct(price, prom_prop) %>%
  mutate(promedio = round(prom_prop)) %>% 
  select(price, promedio)
tabla_perfil <- tabla %>%   
  select(how, price, perfil) %>% 
  spread(how, perfil, fill = -1) 
tabla_2 <- tabla_perfil %>% 
  gather(how, prop_price, -price)

tab_out <- tabla_perfil %>% left_join(precio_prom) %>%
    arrange(desc(`tea bag`)) %>%
    knitr::kable(format = "html", escape = F, digits = 2)
tab_out
```

Leemos esta tabla como sigue: por ejemplo, los compradores de té suelto (`unpacked`) compran té fino (`upscale`) a una tasa casi el doble (0.98) que el promedio. 

También podemos graficar como:

```{r perfiles_grafica, fig.width = 6, fig.height = 2, echo = FALSE, message = FALSE, warning=FALSE}
tabla_ordenada <- tabla %>% 
    ungroup %>% 
    left_join(tabla %>% 
    ungroup %>% 
    filter(how == "tea bag") %>% 
    select(price, perfil_tea = perfil)) %>% 
    mutate(precio = fct_reorder(price, perfil_tea))
g_perfil <- ggplot(tabla_ordenada,
    aes(x = precio, xend = precio, y = perfil, yend = 0, group = how)) + 
    geom_point() + geom_segment() + facet_wrap(~how) +
    geom_hline(yintercept = 0 , colour = "gray") + coord_flip()
g_perfil
```

**Observación**: hay dos maneras de construir la columna promedio: tomando los porcentajes sobre todos los datos, o promediando los porcentajes de las columnas como en este ejemplo.

1. Utiliza bootstrap para crear intervalos de confianza sobre los perfiles de la última tabla.

Primero definimos la funcion bootstrap

```{r perfiles boot}
perfiles_boot <- function(x){
  m <- sample_n(x, size =  300 , replace = TRUE)
  tabla <- m %>% 
    count(how, price) %>% 
    group_by(how) %>% 
    mutate(prop_price = (100 * n / sum(n))) %>% 
    group_by(price) %>% 
    mutate(prom_prop = mean(prop_price)) %>% 
    mutate(perfil = (prop_price / prom_prop - 1) %>% round(2))
  tabla
}
```

Despues corresmos las repeticiones

```{r perfiles_repeticiones, cache=TRUE}
perfiles_rep <- rerun(10000, perfiles_boot(tea)) %>% bind_rows(.id = 'muestra')
```

Posteriormente calculamos los errores estándard

```{r perfiles_errores_est}
perfiles_se <- perfiles_rep %>% 
  group_by(how, price) %>% 
  summarise(se = sd(perfil))
```

Por último calculamos los intervalos

```{r perfiles_intervalos}

perfiles_int <- tabla %>% 
  left_join(perfiles_se) %>% 
  mutate(Int_inf = perfil+qnorm(0.025)*se, Int_sup = perfil+qnorm(0.975)*se)

kable(select(perfiles_int, how, price, perfil, Int_inf, Int_sup), digits = 2)

```


2. Modifica la última gráfica para representar los intervalos de confianza.

```{r perfiles_intervalos_grafica, , fig.width = 6, fig.height = 2, echo = FALSE, message = FALSE, warning=FALSE}
ggplot(perfiles_int) +
  geom_segment(aes(y = price, yend = price, x = Int_inf, xend = Int_sup), size = 1) +
  geom_point(aes(x = perfil, y = price), size = 2) +
  facet_wrap(how~.) +
  labs(x = element_blank(),
       y = element_blank()) +
  theme_light()
```

3. Comenta tus observaciones.
En la categoria de teabag la mayor tasa de compra son los precios "private label y unknown" que son .72 con un intervalo de confianza entre .10 y 1.34. Lo cual nos indica que este patron de comportamiento es alto en esa categoria porque los usuarios de tea compran mas a estos precios y por otro lado compran a una tasa negativa a precio upscale.


#### 2. Cuantificando el error Monte Carlo {-}

Recordemos que ante la pregunta ¿cuántas muestras bootstrap se necesitan? el error que podemos disminuir al aumentar el número de replicaciones es el error de Monte Carlo, y una manera de cuantificarlo es haciendo bootstrap del bootstrap.

Retomemos el ejemplo de la media de las calificaciones de ENLACE de español 3o de primaria en el estado de México. Nos interesa la media de las calificaciones y usaremos el estimador *plug-in*.

```{r enlace}
library(estcomp)
# universo
enlace <- enlacep_2013 %>% 
    janitor::clean_names() %>% 
    mutate(id = 1:n()) %>% 
    select(id, cve_ent, turno, tipo, esp_3 = punt_esp_3, esp_6 = punt_esp_6, 
        n_eval_3 = alum_eval_3, n_eval_6 = alum_eval_6) %>% 
    na.omit() %>% 
    filter(esp_3 > 0, esp_6 > 0, n_eval_3 > 0, n_eval_6 > 0, cve_ent == "15")
set.seed(16021)
n <- 300
# muestra
enlace_muestra <- sample_n(enlace, n) %>% 
    mutate(clase = "muestra")
```

1. Crea un intervalo del 90% para $\hat{\theta}$ usando los percentiles de la distribución bootstrap, y $B=100$ replicaciones.

Primero creamos la función bootstrap

```{r enlace boot}

enlace_boot <- function(x,col){
  col <- enquo(col)
  n <- nrow(x)
  muestra <- sample_n(x,n, replace = TRUE)
  muestra %>% 
    select(!!col) %>% 
    unlist() %>% 
    median()
}
```

Posteriormente se hacen las $B=100$ simulaciones bootstrap.

```{r enlace repeticiones}
enlace_rep <- rerun(100, enlace_boot(enlace,esp_3))%>%
  flatten_dbl()
```

Por último, calculamos el intervalos usando los percentiles de la distrubucion bootstrap.
```{r enlace intervalo}
quantile(enlace_rep, c(0.05, 0.95))
```


2. Podemos estimar el error estándar de Monte Carlo de los extremos de los intervalos (percentiles 0.05 y 0.95) haciendo bootstrap de la distribución bootstrap:
  + Selecciona muestras con reemplazo de tamaño $B$ de la distribución bootstrap,
  + Calcula los percentiles de interés (0.05 y 0.95),
  
Primero construimos la función bootstrap de la distribución bootstrap
```{r enlace muestra bootstrap}
enlace_boot_boot <- function(x){
  n <- length(x)
  muestra <- sample(x, size = n, replace = TRUE)
  tibble(SE_inf = quantile(muestra, c(0.025,0.975))[1], SE_sup = quantile(muestra, c(0.025,0.975))[2])
}
```

Con la función hacemos las repeticiones

```{r enlace boot repeticiones, cache=TRUE}
enlace_boot_rep <- rerun(1000,enlace_boot_boot(enlace_rep)) %>%
  bind_rows(.id = 'muestra')
```


  + Calcula la desviación estándar de los percentiles (una para cada extremo), esta será tu aproximación al error de Monte Carlo
```{r enlace boot es}
EMC100 <- map_dbl(enlace_boot_rep, sd)
```



3. ¿Cuál es el error estándar de Monte Carlo con $B = 100, 1000, 10000$ replicaciones para cada extremo del intervalo de percentiles?

Para el caso de $B = 100$

```{r enlace MC100}
EMC100[2:3]
```

Para el caso de $B = 1000$
```{r enlace MC1000, cache=TRUE}
enlace_rep <- rerun(1000, enlace_boot(enlace,esp_3))%>%flatten_dbl()
enlace_boot_rep <- rerun(1000,enlace_boot_boot(enlace_rep)) %>%
  bind_rows(.id = 'muestra')
map_dbl(enlace_boot_rep, sd)[2:3]
```

Para el caso de $B = 10000$
```{r enlace MC10000, cache=TRUE}
enlace_rep <- rerun(10000, enlace_boot(enlace,esp_3))%>%flatten_dbl()
enlace_boot_rep <- rerun(1000,enlace_boot_boot(enlace_rep)) %>%
  bind_rows(.id = 'muestra')
map_dbl(enlace_boot_rep, sd)[2:3]
```

Las corridas muestran la que el error Monte Carlo va disminuyendo conforme se aumentan el número de replicaciones.

#### 3. Cobertura de intervalos de confianza {-}

En este problema realizarás un ejercicio de simulación para comparar la exactitud de distintos intervalos de confianza. Simularás muestras de una distribución Poisson con parámetro $\lambda=2.5$ y el estadístico de interéses $\theta=exp(-2\lambda)$.

Sigue el siguiente proceso:

i) Genera una muestra aleatoria de tamaño $n=60$ con distribución $Poisson(\lambda)$, parámetro $\lambda=2.5$ (en R usa la función `rpois()`).

ii) Genera $10,000$ muestras bootstrap y calcula intervalos de confianza del 95\% para $\hat{\theta}$ usando 1) el método normal, 2) percentiles y 3) $BC_a$.


Primero definimos la función del parámetro
```{r poisson boot}
poiss_boot <- function(x, ind){
  exp(-2*mean(x[ind]))
}
```

Posteriormente definimos la funcion que genera los intervalos de confianza

```{r poisson intervalos}
poiss_intervalos <- function(n=60) {
  poiss_muestra <- rpois(n,2.5)
  
  poiss_rep <-  boot(poiss_muestra, poiss_boot,10000)
  poiss_int <-boot.ci(poiss_rep, type = c("norm", "perc", "bca"))
  
  data.frame(metodo = c('normal','percentil','BCa'),
             theta = poiss_int$t0,
             inferior = c(poiss_int$normal[2],poiss_int$percent[4],poiss_int$bca[4]),
             superior = c(poiss_int$normal[3],poiss_int$percent[5],poiss_int$bca[5]))
}
```

Finalmente, los intervalos son:
```{r poisson intervales}
poiss_intervalos() %>% 
  kable(digits = 4)
```

iii) Revisa si el intervalo de confianza contiene el verdadero valor del parámetro ($\theta=exp(-2\cdot2.5)$), en caso de que no lo contenga registra si falló por la izquierda o falló por la derecha.

Los tres intervalos de confianza contienen el verdadero valor del parámetro `r exp(-2*2.5)`

a) Repite el proceso descrito 1000 veces y llena la siguiente tabla:

Primero corremos las 100 repeticiones

```{r poisson repeticiones, cache=TRUE}
poiss_rep_int <- rerun(1000, poiss_intervalos()) %>% bind_rows(.id = 'muestra')
```

Posteriormente calculamos los fallos y combertura

```{r poisson fallos}
poiss_rep_int <- poiss_rep_int %>% 
  mutate(fallo_izquierda = exp(-2*2.5)<inferior,
         fallo_derecha = exp(-2*2.5)>superior,
         Longitud = superior-inferior)
```

Así tenemos la siguiente tabla:

```{r poisson tabla}
poiss_rep_int %>% 
  group_by(metodo) %>% 
  summarise(P_fallo_izquierda = sum(fallo_izquierda)/n(),
            P_fallo_derecha = sum(fallo_derecha)/n(),
            Cobertura = 1 - P_fallo_izquierda - P_fallo_derecha,
            Longitud_promedio = mean(Longitud)) %>% 
  kable()
```


La columna cobertura es una estimación de la cobertura del intervalo basada en las simulaciones, para calcularla simplemente escribe el porcentaje de los intervalos que incluyeron el verdadero valor del parámetro. La longitud promedio es la longitud promedio de los intervalos de confianza bajo cada método.

b) Realiza una gráfica de páneles, en cada panel mostrarás los resultados de uno de los métodos (normal, percentiles y BC_a), en el vertical graficarás los límites de los intervalos.

```{r poisson grafica}
  ggplot(poiss_rep_int) +
    geom_pointrange(aes(x = reorder(muestra,theta),
                        ymin = inferior,
                        y=theta,
                        ymax = superior),
                    size=0.2) +
    geom_hline(yintercept = exp(-2.5*2)) +
    facet_grid(metodo~.)
```


c) Repite los incisos a) y b) seleccionando muestras de tamaño $300$.


Primero hacemos las repeticiones con el tamano de muestra 300.

```{r poisson 300, cache=TRUE}
poiss_rep_int_300 <- rerun(1000, poiss_intervalos(300))%>%
  bind_rows(.id = 'muestra') %>% 
  mutate(fallo_izquierda = exp(-2*2.5)<inferior,
         fallo_derecha = exp(-2*2.5)>superior,
         Longitud = superior-inferior)
```

Así obtenemos la siguiente tabla:


```{r poisson tabla 300}
poiss_rep_int_300 %>% 
  group_by(metodo) %>% 
  summarise(P_fallo_izquierda = sum(fallo_izquierda)/n(),
            P_fallo_derecha = sum(fallo_derecha)/n(),
            Cobertura = 1 - P_fallo_izquierda - P_fallo_derecha,
            Longitud_promedio = mean(Longitud))%>% 
  kable()
```

Y la siguiente gráfica:

```{r poisson grafica 300}
  ggplot(poiss_rep_int_300) +
    geom_pointrange(aes(x = reorder(muestra,theta),
                        ymin = inferior,
                        y=theta,
                        ymax = superior),
                    size=0.2) +
    geom_hline(yintercept = exp(-2.5*2)) +
    facet_grid(metodo~.)
```
